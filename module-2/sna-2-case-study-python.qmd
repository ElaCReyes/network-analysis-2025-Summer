---
title: 'A Tale of Two MOOCs'
subtitle: "SNA Module 2: Case Study"
author: "LASER Institute"
date: today 
format:
  html:
    toc: true
    toc-depth: 4
    toc-location: right
theme:
  light: simplex
  dark: cyborg
editor: visual
jupyter: python3
bibliography: lit/references.bib
---

## 1. Prepare

For our second case study, *A Tale of Two MOOCs*, we move beyond visual depictions of networks from our previous SNA case study and learn to describe networks using common network-level measures. Our analyses are based on *A social network perspective on peer supported learning in MOOCs for educators* [@kellogg2014social], and use an open educational dataset prepared by Kellogg and Edelman @kellogg2015massively. As we work through each step of the data-intensive workflowÂ (Krumm, Means, and Bienkowski 2018), we will focus on the following topics:

1.  **Prepare**: Prior to analysis, we'll take a look at the context from which our data came and load various Python packages for data science and network analysis.

2.  **Wrangle**: In section 2 we make use of the {pandas} and {networkx} packages to import and prepare relational data stored as as an adjacency matrix.

3.  **Explore**: In our prior case study, we indirectly used the {networkx} package on which {p`ygraphviz`} depends. In section 3, we use {igraph} directly to calculate a range of network-level measures to describe and compare collaboration networks over time.

4.  **Model**: While we don't do any modeling of our data in this case study, we dive a little deeper into work of Kellogg et al. to see how modeling can was used to examine MOOC-Ed discussion networks.

5.  **Communicate**: Finally, we prepare a simple "data product" consisting of a data visualization and/or table that highlights some key findings from our analysis.

### 1a. Review the Research

#### A Social Network Perspective in MOOC-Eds {data-link="A Social Network Perspective in MOOC-Eds"}

![](img/irrodl-article.png){width="50%"}

Kellogg, S., Booth, S., & Oliver, K. (2014). [A social network perspective on peer supported learning in MOOCs for educators](https://github.com/sbkellogg/eci-589/blob/main/unit-1/lit/sna_mooc_irrodl_bjet_articles.pdf).Â *International Review of Research in Open and Distributed Learning*,Â *15*(5), 263-289.

#### Research Context

In the spring of 2013, The Friday Institute launched the MOOC-Ed Initiative to explore the potential of delivering personalized, high-quality professional development to educators at scale (Kleiman et al., 2013). In collaboration with the Alliance for Excellent Education, the Friday Institute launched this initiative with a 6-week pilot course called Planning for the Digital Learning Transition in K-12 Schools (DLT 1), which was offered again in September 2013 (DLT 2). This course was designed to help school and district leaders plan and implement K-12 digital learning initiatives.

Academics, as well as pundits from traditional and new media, have raised a number of concerns about MOOCs, including the lack of instructional and social supports. Among the core design principles of MOOC-Eds are collaboration and peer-supported learning. It is an assumption of this study that challenges arising form this problem of scale can be addressed by leveraging these massive numbers to develop robust online learning communities.

This mixed-methods case study used both SNA and qualitative methods to better understand peer support in MOOC-Eds through an examination of the characteristics, mechanisms, and outcomes of peer networks. Findings from this study demonstrate that even with technology as basic as a discussion forum, MOOCs can be leveraged to foster these networks and facilitate peer-supported learning. Although this study was limited to two unique cases along the wide spectrum of MOOCs, the methods applied provide other researchers with an approach for better understanding the dynamic process of peer supported learning in MOOCs.

#### Data Sources

**MOOC-Ed registration form.** All participants completed a registration form for each MOOC-Ed course. The registration form consists of self-reported demographic data, including information related to their professional role and work setting, years of experience in education, and personal learning goals.

**MOOC-Ed discussion forums.** All peer interaction, including peer discussion, feedback, and reactions (e.g., likes), take place within the forum area of MOOC-Eds, which are powered by Vanilla Forums. Because of the specific focus on peer supported learning, postings to or from course facilitators and staff were removed from the data set. Finally, analyses described below exclude more passive forms of interactions (i.e., read and reaction logs), and include only postings among peers.

For our second case study, we'll take a look at data from the original Digital Learning Transition in K-12 Schools (DLT 1) that was not included in this study.

**Note**: In the data we're using, instructors have not yet been removed and only direct replies to forum posts have been included, though "weaker" ties like reactions with emoticons and even views of posts were captured in this study.

#### **ðŸ‘‰ Your Turn** **â¤µ**

Take a quick look at the *Description of the Dataset* section from the [Massively Open Online Course for Educators (MOOC-Ed) network dataset](https://github.com/laser-institute/essential-readings/blob/main/sna-labs/sna-lab-2/bjet_12312_Rev.pdf) BJET article and the accompanying data sets stored on [Harvard Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/ZZH3UB) that we'll be using for this case study.

In the space below, type a brief response to the following questions:

1.  What were some of the steps necessary to construct the edges in this dataset?

    -   YOUR RESPONSE HERE

2.  What "node attributes" are included in this dataset? How might they be used for analysis?

    -   YOUR RESPONSE HERE

3.  What basic network-level descriptives were included in this article?

    -   YOUR RESPONSE HERE

4.  What else do you notice/wonder about this dataset?

    -   YOUR RESPONSE HERE

### 1b. Identify a Question(s)

A Social Network Perspective on Peer Supported Learning was framed by three primary research questions related to peer supported learning:

1.  What are the patterns of peer interaction and the structure of peer networks that emerge over the course of a MOOC-Ed?

2.  To what extent do participant and network attributes (e.g., homophily, reciprocity, transitivity) account for the structure of these networks?

3.  To what extent do these networks result in the co-construction of new knowledge?

For Lab 2, our exploratory analysis is primarily interested in answering some rather basic questions:

1.  How do the DLT 1 and DLT 2 MOOC-Ed networks compare visually?

2.  How do network-levels measures for each network compare?

3.  What do these visual and mathematical descriptions of our network imply about the similarities and differences in the "patterns of peer-interaction" between each MOOC-Ed?

#### **ðŸ‘‰ Your Turn** **â¤µ**

Based on what you know about networks and the context so far, what other research question(s) might ask we ask in this context that a social network perspective might be able to answer?

-   YOUR RESPONSE HERE

### 1b. Load Libraries

A Python package or library is a collection of modules that offer a set of functions, classes, and variables that enable developers and data analysts to perform many tasks without writing their code from scratch. These can include everything from performing mathematical operations to handling network communications, manipulating images, and more.

#### pandas ðŸ“¦

![](img/pandas.svg){width="30%"}

One package that we'll be using extensively is {pandas}. [Pandas](https://pandas.pydata.org) [@mckinney-proc-scipy-2010] is a powerful and flexible open source data analysis and wrangling tool for Python that is used widely by the data science community.

Click the green arrow in the right corner of the "code chunk" that follows to load the {pandas} library introduced in LA Workflow labs.

```{python}
import pandas as pd
import networkx as nx                  
import matplotlib.pyplot as plt        
import  scipy as sp
```

## 2. Wrangle

In general, data wrangling involves some combination of cleaning, reshaping, transforming, and merging data[@wickham2016r]. As highlighted inÂ Estrellado et al. @estrellado2020e, wrangling network data can be even more challenging than other data sources since network data often includes variables about both individuals and their relationships. For data wrangling in this lab, we're keeping it simple since working with relational data, especially in the form of matrices, is a bit of a departure from our working with rectangular data frames.

For our data wrangling this week, we're keeping it simple since working with network data is a bit of a departure from our working with rectangular data frames. Our primary goals for Section 2 are learning how to:

a.  **Import Data**. An obvious and also important first step, we need to "read" our data into R and learn about formatting for edge-lists and node attribute files.

b.  **Create a Graph Object**. Before performing network analyses, we'll need to convert our data frames into a graph object for working with relational data.

### 2a. Import Data

#### The Edge-List Format

To get started, we need to import, or "read", our data into Python. The function used to import your data will depend on the file format of the data you are trying to import, but R is pretty adept at working with many files types.

Take a look in the `/data` folder in your Files pane. You should see the following .csv files:

-   `dlt1-edges.csv`

-   `dlt1-nodes.csv`

The first file `dlt1-edges.csv` is an edge-list that contains information about each tie, or relation between two actors in a network. In this context, a "tie" is a reply by one participant in the discussion forum to the post of another participant -- or in some cases to their own post! These ties between a single actor are called "self-loops" and as we'll see later, networkx has a special function to remove these self loops from a sociogram, or network visualization.

The edge-list format is slightly different than other formats you have likely worked with before in that the values in the first two columns each row represent a dyad, or tie between two nodes in a network. An edge-list can also contain other information regarding the strength, duration, or frequency of the relationship, sometime called "weight", in addition to other "edge attributes."

In addition to our `Sender` and `Reciever` dyad pairs, our DLT 1 dataset contains the following edge attributes:

-   `Sender` = Unique identifier of author of comment

-   `Receiver` = Unique identifier of identified recipient of comment

-   `Timestamp` = Time post or reply was posted

-   `Parent` = Primary category or topic of thread

-   `Category` = Subcategory or subtopic of thread

-   `Thread_id` = Unique identifier of a thread

-   `Comment_id` = Unique identifier of a comment\\

Let's use the `read_csv()` function from the {readr} and {janitor} packages introduced in previous units to read in our edge-list and clean up the variables names:

```{python read_edges}
import pandas as pd

# Read CSV and exclude 'Category Text' column
dlt1_ties = pd.read_csv(
    "data/dlt1-edges.csv",
    dtype={
        'Sender': 'str',
        'Receiver': 'str',
        'Comment ID': 'str',
        'Discussion ID': 'str'
    },
    usecols=lambda column: column not in ['Category Text']
)

# Clean column names
dlt1_ties.columns = dlt1_ties.columns.str.lower().str.replace(' ', '_')

# Display the DataFrame
print(dlt1_ties)

```

Note the addition of the `col_types =` argument for changing the column types to character strings since the numbers for those particular columns indicate actors (`Sender` and `Reciever`) and attributes (`Comment_ID` and `Discussion_Id`). We also skipped the `Category Text` since this was left blank for deidentification purposes.

#### **ðŸ‘‰ Your Turn** **â¤µ**

Consider the example pictured below of a discussion thread from the Planning for the Digital Learning Transition in K-12 Schools (DLT 1) where our data originated. This thread was initiated by participant I, so the comments by J and N are considered to be directed at I. The comment of B, however, is a direct response to the comment by N as signaled by the use of the quote-feature as well as the explicit mentioning of N's name within B's comment.

![](img/discussion-thread.png)

Now answer the following questions as they relate to the DLT 1 edge-list we just read into R.

1.  Which actors in this thread are the `Sender` and the `Reciever`? Which actor is both?

    -   YOUR RESPONSE HERE

2.  How many dyads are in this thread? Which pairs of actors are dyads?

    -   YOUR RESPONSE HERE

**Sidebar:** Unfortunately, these types of nuances in discussion forum data as illustrated by this simple example are rarely captured through automated approaches to constructing networks. Fortunately, the dataset you are working with was carefully reviewed to try and capture more accurately the intended recipients of each reply.

#### Node Attributes

The second file we'll be using contains all the nodes or actors (i.e., participants who posted to the discussion forum) as well as some of their attributes such as gender and years of experience in education.

Carolan (2013) notes that most social network analyses include variables that describe attributes of actors, ones that are either categorical (e.g., sex, race, etc.) or continuous in nature (e.g., test scores, number of times absent, etc.). These attributes that can be incorporated into a network graph or model, making it more informative and can aid in testing or generating hypotheses.

These attribute variables are typically included in a rectangular array, or dataframe, that mimics the actor-by-attribute that is the dominant convention in social science, i.e. rows represent cases, columns represent variables, and cells consist of values on those variables.

As an aside, Carolan also refers to this historical preference by researchers for "actor-by-attribute" data, in the absence of relational data in which the actor has been removed their social context, as the "sociological meatgrinder" in action. Specifically, this historical approach assumes that the actor does not interact with anyone else in the study and that outcomes are solely dependent of the characteristics of the individual.

Let's use the code chunk below to import the `dlt1-nodes.csv` attribute file and be sure to set the following variables as character data types: `UID`, `Facilitator`, `expert`, `connect`.

```{python read_nodes}
# YOUR CODE HERE
# Read the CSV file and specify the data types for certain columns
dlt1_actors = pd.read_csv("data/dlt1-nodes.csv",
                          dtype={
                              'UID': 'str',
                              'Facilitator': 'str',
                              'expert': 'str',
                              'connect': 'str'
                          })

# Clean column names: convert to lowercase and replace spaces with underscores
dlt1_actors.columns = dlt1_actors.columns.str.lower().str.replace(' ', '_')

# Display the DataFrame
print(dlt1_actors)

```

#### **ðŸ‘‰ Your Turn** **â¤µ**

Now use the code chunk below to inspect the data you imported and complete the matching exercise that follows:

```{python}
#YOUR CODE HERE

# Display the DataFrame

```

Match up the attributes included in the node file with the following codebook descriptors. The first one has been done as an example.

-   `Facilitator` = Identification of course facilitator (1 = instructor)
-   Dummy variable for whether participants listed networking and collaboration with others as one of their course goals on the registration form
-   Identifier of "expert panelists" invited to course to share experience through recorded Q&A
-   Identification of course facilitator (1 **=** instructor)
-   Professional role (e.g., teacher, librarian, administrator)
-   Years of experience as an educator
-   Works with elementary, middle, and/or high school students
-   Initial assignment of discussion group

### 2b. Create Network Object

As demonstrated in our previous case study, we first need to convert the data frames that we imported into an network object before we can begin using many of the functions from our network packages for summarizing and visualizing our DLT 1 network.

#### Convert to Graph Object

To do that, we will use the `nx.Graph()` function from the `networkx` package.

Note that I included the `eval=FALSE` argument in the code block below to prevent this code from running when we knit our final document. Otherwise it will produce an error since we can't include help documentation in our knitted HTML file.

Run the following code to take a look at the help documentation for this function:

```{python function_help, executed: false}
?nx.Graph
```

You probably saw that this particular function takes the following three arguments, two of which are data frames:

-   **`edges =`** A `data.frame` containing information about the edges in the graph. The terminal nodes of each edge must either be encoded in a `to` and `from` column, or be in the two first columns.

-   **`nodes =`**Â a node list that starts with a column of node IDs. Any following columns are interpreted as node attributes.

-   **`node_key =`** The name of the column in `nodes` that character represented `to` and `from` columns should be matched against.

-   **`directed =`** determines whether or not to create a directed graph.

Run the following code to specify our `ties` data frame as the edges of our network, our `actors` data frame for the vertices of our network and their attributes, and indicate that this is indeed a directed network.

```{python}
# Create a MultiDiGraph to allow multiple edges
dlt1_network = nx.from_pandas_edgelist(
    dlt1_ties,
    source='sender',
    target='receiver',
    edge_attr=True,
    create_using=nx.MultiDiGraph()
)


dlt1_network.add_nodes_from(dlt1_actors.set_index('uid').to_dict(orient='index').items())
```

#### **ðŸ‘‰ Your Turn** **â¤µ**

Take a look at the output for our `dlt1_network` and answer the questions that follow:

```{python}
#YOUR CODE HERE
#display the dlt1_network network by converting the edge list to a pandas dataFrame and print it


```

1.  How does the number of node and edges in our DLT 1 network compare to the totals reported for the DLT 2, the second iteration of this MOOC-Ed, reported on in our [guiding study](https://github.com/laser-institute/essential-readings/blob/main/sna-labs/sna-lab-2/sna_mooc_irrodl_bjet_articles.pdf)?

    -   YOUR RESPONSE HERE

2.  Do the number of nodes and edges are in our network match the number of observations in our node and edge list .csv files? **Hint:** Check the Environment pane.

    -   YOUR RESPONSE HERE

3.  Our output notes that our network is a directed multigraph, indicating that some dyads may have multiple edges. Why might that be?

    -   YOUR RESPONSE HERE

## 3. Explore

Relevant to our case study of DLT 1 & 2 MOOC-Eds, Carolyn notes in SNA and Education @carolan2014 that:

> ... to address questions that probe a network's dynamics (i.e., its change over time), it is necessary to first figure out what the network looks like at one point in time, what is commonly referred to as the network's topography.

In order to describe a network's **topography**, social network researchers utilize an array of algorithms and indices to describe both visually and numerically different characteristics of social networks. These algorithms and indices rely on both simple and somewhat sophisticated mathematical computation.

In this section, we revisit using methods from Pandas and NetworkX (`tidygraph` equivalent), and matplotlib or plotly packages for visualization (`ggraph` equivalent) for creating sociograms and computing basic node and edge-level measures. We also introduce key functions from the `igraph` package for obtaining comprehensive network-level measures

### 3a. Visually Describe the Network

One of the defining characteristics of the social network perspective is its use of graphic imagery to represent actors and their relations with one another. To emphasize this point, Carolyn (2013) reported that:

> The visualization of social networks has been a core practice since its foundation more than 90 years ago and remains a hallmark of contemporary social network analysis.Â 

Network visualization can be used for a variety of purposes, ranging from highlighting key actors to even serving as works of art. Katya Ognyanova's also excellent tutorial on [Static and Dynamic Network Visualization with R](https://kateto.net/network-visualization/) helps illustrate the variety of goals a good network visualization can accomplish.

Recall from our previous SNA case study examining student friendships in middle school that we introduced the simple Matplotlib draw function [`draw()`](https://networkx.org/documentation/stable/reference/drawing.html) to quickly generate a sociogram showing the nodes and edges in our network.

Let's supply our `year-1-network` object as the first argument to each of these functions and see what they produce:

```{python}
nx.draw(dlt1_network)
plt.show()
plt.clf()
```

```{python}
#nx.draw_networkx(dlt1_network,pos=nx.spring_layout(dlt1_network))
#plt.show()
nx.draw(dlt1_network, with_labels=True)
plt.show()
plt.clf()
```

Yuck! Neither a aesthetically pleasing plot, nor terribly functional. As indicated by our tidy graph output from section 1, however, we can see that there is one large network component and three additional components consisting of isolated MOOC-Ed participants who neither sent or received replies to their colleagues.

As you may have realized already, the utility of the basic `plt()` function is not very useful for large networks like this one. Fortunately, the matplotlib.pyplot package that we learned about in Lab 1 includes a plethora of plotting parameters for graph [layouts](https://ggraph.data-imaginist.com/articles/Layouts.html), [edges](https://ggraph.data-imaginist.com/articles/Edges.html) and [nodes](https://ggraph.data-imaginist.com/articles/Nodes.html) to improve the visual design and readability of network graphs.

**Note:** If you're having trouble seeing the plot you can run the code in the console and see the plot in the Viewer pane or click the little arrow/window icon in the output of the code chunk to open the plot in a new window and resize.

**Creating Sociograms with NetworkX**

Similar to its `ggplot` counterpart for traditional charts and graphs, creating sociograms with NetworkX involves a minimal code template. This template consists of three main components:

1.  **Layout Setup and Plot Initialization:** NetworkX uses functions like `nx.draw()` to initialize the plot object and set up the graph layout. Various layout algorithms are available, such as `nx.spring_layout()` or `nx.circular_layout()`.

2.  **Node Customization:** To add nodes to the network plot and modify their visual attributes, use functions like `nx.draw_networkx_nodes()` and `nx.draw_networkx_labels()` along with their associated arguments.

3.  **Edge Customization:** Adding edges to the network plot and modifying their visual attributes can be done using functions like `nx.draw_networkx_edges()` and adjusting edge attributes as needed.

These core functions can be further customized using additional layers of functions or by adjusting arguments to emphasize specific network characteristics such as edge weights or central nodes.

Let generate the same basic plot above but explicitly call our networkx, node, and edge functions:

```{python}

plt.figure(figsize=(8, 6))

pos = nx.kamada_kawai_layout(dlt1_network)

# Draw edges
nx.draw_networkx_edges(dlt1_network, pos, alpha=0.5)

# Draw nodes
nx.draw_networkx_nodes(dlt1_network, pos, node_size=20, node_color='black', alpha=0.8)

#nx.draw(dlt1_network)

plt.axis('off')
plt.show()
plt.clf()
```

We won't spend a lot of time on polishing our graph here. We'll save that effort for when we are ready to communicate our findings to a specific audience, but lets make some quick functional and aesthetic changes: Run the following code to:

-   Change the graph layout to the kamada_kawai_layout layout using the `nx.kamada_kawai_layout()` argument to help highlight areas of clustering;

-   Decrease the transparency of our edges using the `alpha =` argurment the to better highlight the nodes;

-   Change the size of our nodes using the nx.draw_networkx_edges function to make those more connected more visible;

-   Change the color of our nodes based on their school or district role using the nx.draw_networkx_nodes function and the node_color= argument; and,

-   Set plt.axis to off to remove the axis.

```{python}

node_roles = nx.get_node_attributes(dlt1_network, 'role1')
node_sizes = [len(list(dlt1_network.neighbors(node))) * 100 for node in dlt1_network.nodes]

pos = nx.kamada_kawai_layout(dlt1_network)

unique_roles = set(node_roles.values())  # Get unique roles
color_map = plt.get_cmap('tab20', len(unique_roles))  # Choose a colormap and number of colors
role_colors = {role: color_map(i) for i, role in enumerate(unique_roles)}
node_colors = [role_colors[node_roles[node]] for node in dlt1_network.nodes()]


plt.figure(figsize=(20, 15))

# Draw edges with transparency (alpha)
nx.draw_networkx_edges(dlt1_network, pos, alpha=0.2)

# Draw nodes with colors and sizes
nx.draw_networkx_nodes(dlt1_network, pos, node_size=node_sizes, node_color=node_colors, alpha=0.8)

plt.axis('off')

plt.show()
plt.clf()
```

That is perhaps slightly better, but before sharing with an education partner, I would likely do quite a bit more clean up to highlight key findings specific to network measures that we'll explore in the next section.

**Note:** If you're having difficulty seeing the sociogram in the small R Markdown code chunk, you can copy and paste the code in the console and it will show in the Viewer pan and then you can enlarge and even save as an image file.

#### ðŸ‘‰ Your Turn â¤µ

Use the code chunk below created a sociogram for the DLT 2 MOOC network and answer the questions that follow:

```{python year_3_sociogram}

#YOUR CODE HERE

# Read dlt2-edges csv and exclude 'Category Text' column


# Clean column names


# Display the DataFrame


# Read dlt2-nodes csv


# Clean column names: convert to lowercase and replace spaces with underscores


# Display the DataFrame


# Create a MultiDiGraph from the dlt2_ties pandas DataFrame


#display the dlt2_network network by converting the edge list to a pandas dataFrame and print it

```

```{python year_3_sociogram}

# extract the 'role' attribute for all nodes in the 'dlt2_network'
node_roles = nx.get_node_attributes(dlt2_network, 'role')

# calculate the size of each node based on the number of its neighbors and extract the node sizes
node_sizes = [len(list(dlt2_network.neighbors(node))) * 100 for node in dlt2_network.nodes()]

# compute the positions of the nodes in the graph using layout algorithm
pos = nx.kamada_kawai_layout(dlt2_network)

# Get unique roles and assign colors
unique_roles = sorted(set(node_roles.values()))
color_map = plt.get_cmap('tab20', len(unique_roles))
role_colors = {role: color_map(i) for i, role in enumerate(unique_roles)}
default_color = (0.5, 0.5, 0.5, 1.0)

# Assign colors to nodes 
node_colors = [role_colors.get(node_roles.get(node, None), default_color) for node in dlt2_network.nodes()]

plt.figure(figsize=(20, 15))
nx.draw_networkx_edges(dlt2_network, pos, alpha=0.2)
nx.draw_networkx_nodes(dlt2_network, pos, node_size=node_sizes, node_color=node_colors, alpha=0.8)
plt.axis('off')
plt.show()
plt.clf()
```

1.  How does the DLT 2 network compare to DLT 1? What are some similarities and differences?

    -   YOUR RESPONSE HERE

2.  How might you modify this graph to make it more insightful and useful? For ideas check out these nework viz tutorials [here](http://mr.schochastics.net/netVizR.html), [here](https://kateto.net/network-visualization) and [here](https://rpubs.com/neloe/ggraph_intro).

    -   YOUR RESPONSE HERE

### 3b. Describe the Network Mathematically

This section include some of the most common measures used to describe the features of complete networks, both at the network-level measures and also for individual nodes as well. Recall from our essential readings that:

> Network-level structural measures are those that are calculated from the entire network. Therefore, they provide an excellent snapshot of the network's structure---the pattern of relations among the network's actors.

In addition to providing an overall summary of the network, these measures provide a concrete means to compare relations such as whether the friendship, social support, and advice seeking networks within the same fraternity, for example, are comparable. In our case study, for example, were are

#### 1. Network Size

One simple but important property of a social network is its size, or the number of nodes and edges in a network. As Carolan notes:

> Size plays an important role in determining what happens in the network--- what resources are exchanged among actors, for example... Size affects other network measures, but on a conceptual level, it influences the structure of relations, as actors only have so many resources and capacities for creating and maintaining ties with others.

As we saw in the previous section, the `dlt1_network` output provided us with basic information about our networks size, including the number of nodes and edges in our network. The {networkx} package also has some basic functions for retrieving the number of nodes and edges in a network.

Run the following code chunk to use the [`network.number_of_nodes()`](https://networkx.org/documentation/stable/reference/classes/generated/networkx.Graph.number_of_nodes.html) and [`network.number_of_edges()`](https://networkx.org/documentation/stable/reference/classes/generated/networkx.Graph.number_of_edges.html) functions obtain the number of vertices and edges respectively:

```{python compute_size}
#Number of nodes
dlt1_network.number_of_nodes()
#Number of edges
dlt1_network.number_of_edges()

dlt1_network.size() #gives you the number of edges as well


```

#### 2. Centralization

A key structural property of complete networks, and often the focus of network studies is the concept of centralization, or the extent to which relations are focused on one or a small set of actors. Centralization is an important concept in network because, as Carolan notes:

> Central actors likely wield a disproportionate amount of influence on the network. Therefore, high centralization provides fewer actors with more power and control.

Centralization can be based on a number of different measures, but degree is one of the most common. Degree refers to the number of ties an actor either sends (out-degree), receives (in-degree), or in the case of a non-directed network or both sent and received in a directed network, simply just "degree" for all actors to which one is connected.

The [`degree_centrality()`](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.degree_centrality.html#networkx.algorithms.centrality.degree_centrality) function in {networkx} computes the degree centrality for nodes.

Degree centrality values are normalized by dividing each node's degree by nâˆ’1n-1nâˆ’1, where n is the total number of nodes in the dlt1_network. Because dlt1_network is a multidigraph with self-loops, the maximum degree can exceed nâˆ’1n-1nâˆ’1, resulting in degree centrality values that can be greater than 1.

Let's first take a look at the centralization measure based on number of actors individuals have ties with regardless of directionality:

### Steps to Calculate the Centralization Score:

1.  **Compute the degree of each node.**

2.  **Determine the maximum possible centralization (theoretical max).**

3.  **Calculate the actual centralization. (revisit and discus the difference in using the degree_centrality package and using the steps)**

```{python}

nx.degree(dlt1_network)
```

```{python}

dlt1_network_centrality = dict(dlt1_network.degree())

# Maximum degree in the network
max_degree = max(dlt1_network_centrality.values())

# Sum of differences between max degree and all other degrees
degree_sum = sum(max_degree - degree for degree in dlt1_network_centrality.values())

# Number of nodes in the graph
n = dlt1_network.number_of_nodes()

# Theoretical maximum centralization for a network with n nodes
theoretical_max = (n - 1) * (n - 2)
    
print(theoretical_max)

# Centralization score
centralization = degree_sum / theoretical_max if theoretical_max != 0 else 0
    
print(centralization)
```

dlt1_network.degree() provides node-level centrality scores. So for example, the first MOOC-Ed participant in our network is connected to 53 other actors in the network.

Let's also take a quick look at centralization scores for in-degree and out-degree:

```{python compute_degrees}
in_degrees = dict(dlt1_network.in_degree())
out_degrees = dict(dlt1_network.out_degree())
print("in-degree centrality:", in_degrees)
print("Out-degree centrality:", out_degrees)
```

```{python compute_centrality}

#Determine the Maximum Degree
max_in_degree = max(in_degrees.values())
max_out_degree = max(out_degrees.values())


#Sum of Degree Differences
sum_in_degree_diff = sum(max_in_degree - deg for deg in in_degrees.values())
sum_out_degree_diff = sum(max_out_degree - deg for deg in out_degrees.values())

#Calculate Theoretical Maximum Centralization
n = dlt1_network.number_of_nodes()
max_centralization = (n - 1) * (n - 2)
print("Theoretical Maximum centralization:", max_centralization)

#Compute Actual Centralization Score
centralization_in = sum_in_degree_diff / max_centralization if max_centralization != 0 else 0
centralization_out = sum_out_degree_diff / max_centralization if max_centralization != 0 else 0

print("in-centrality Score:",centralization_in)
print("Out-centrality Score:", centralization_out)

```

Again, we still have a rather centralized graph, especially for in-degree which suggest that a few individual may be receiving an outsized share of replies.

While our primary concern is complete network-level measures so we can compare DLT 1 & DLT 2 networks, obtaining node-level measures is also very useful for helping to describe the network, particularly for visualization. For example, we might want to adjust the size of nodes in a network based on degree, so those actors with more connections stand out more prominently.

The networkx package and the pandas library that allows us to treat the nodes and edges in our network object as if they were a standard data frame that we can then functions to like `select`, `filter`, and `modify`.

-   NetworkX provides methods to iterate over nodes and edges (`G.nodes()` and `G.edges()` respectively), which allows you to effectively "select" nodes or edges based on certain criteria.

-   You can filter nodes or edges based on specific criteria using list comprehensions or filter functions in Python

-   Modify the graph structure (adding or removing nodes or edges based on conditions), use NetworkX's methods like `G.add_node()`, `G.add_edge()`, `G.remove_node()`, and `G.remove_edge().`These can be used with the nx.degree() function to create new variables for node-level measures of degree, in-degree, and out-degree.

    The set_node_attributes() function can also be used to add attributes to nodes in a graph.

Run the following code to add each actor's `in-degree` (i.e. number of replies received) to our DLT 1 network and assign the output `dlt1_network` again so the results are saved:

```{python}
nx.set_node_attributes(dlt1_network, in_degrees, 'in_degree')

```

Let's temporarily convert to a data frame so we can get a better look at our nodes and the measure of `degree`

```{python}

dlt1_networkNodes = (dlt1_network.nodes(data=True))

# Convert to DataFrame
dlt1_network_df = pd.DataFrame(dlt1_networkNodes, columns=['uid', 'Attributes'])

# Expand the 'Attributes' column into separate columns
dlt1_network_df_expanded = pd.concat([dlt1_network_df['uid'], dlt1_network_df['Attributes'].apply(pd.Series)], axis=1)

#print(dlt1_network_df_expanded)
print(dlt1_network_df_expanded.sort_values(by='uid', ascending=True)) #check
```

Now we can also adjust the size of more central actors in our sociogram from above using `in_degree` instead of `local_size()` to highlight those actors who are receiving an outsized share of replies:

```{python udpate_sociogram}
# dlt1_network is graph and in_degree is already calculated
plt.figure(figsize=(8, 6))
pos=nx.spring_layout(dlt1_network)

# Draw edges with reduced alpha
nx.draw_networkx_edges(dlt1_network, pos=pos, alpha=0.2)

# Draw nodes with size based on in-degree and color based on 'role1'
node_sizes = [dlt1_network.nodes[n]['in_degree'] * 100 for n in dlt1_network.nodes()]
node_colors = [dlt1_network.nodes[n]['role1'] for n in dlt1_network.nodes()]
cmap = plt.cm.viridis
nx.draw_networkx_nodes(dlt1_network, pos=pos, node_size=node_sizes, node_color=node_colors, cmap=plt.cm.viridis, alpha=0.8)

# Customize the plot (optional)
plt.title('Graph with Node Size by In-Degree and Color by Role')
sm = plt.cm.ScalarMappable(cmap=cmap)
sm.set_array(node_colors)
plt.colorbar(sm, label='Role')
plt.axis('off')

# Show the plot
plt.show()
```

#### 3. Density

Since we know the number of ties, or edges, in our network, we can examine the overall density of our network, which is directly linked to network size. As Carolan explains:

> Density refers to the number of ties in the network reported as a fraction of the total possible number of ties... The closer this number is to 1.0, the denser the network.

In NetworkX, you can calculate the density of a network using the `density()` function

```{python compute_density}

# Edge density
nx.density(dlt1_network)

```

As you can see, our collaboration network in DLT 1 has a VERY low density. Interpretation of the measure greatly depends on context, however. In smaller networks, for example, it may suggest that collaboration in the network is quite limited and may impact the flow of information, resources, and innovations among actors. In a large network like this one, however, low density is very common. Moreover, even though someone may not have given or received replies very often to others, they still benefit in that since this in an online discussion, all information shared is visible to all participants.

#### 4. Reciprocity

Reciprocity is an important measure because it reveals the direction through which resources in networks flow and whether or not it flows in both directions. The tendency towards reciprocity in most networks, sometimes referred to as the "norm" of reciprocity, has been acknowledge by ancient writers such as Cicero who stated:

> There is no duty more indispensable than that of returning a kindness... all men distrust one forgetful of a benefit.

At the network-level, reciprocity is defined as reciprocity is **a measure of the likelihood of vertices in a directed network to be mutually linked**. Using the [`reciprocity()`](https://igraph.org/r/html/latest/reciprocity.html) function, we can directly calculate this measure:

```{python compute_reciprocity}

nx.reciprocity(dlt1_network)
```

As illustrated by the reciprocity measure above, the tendency towards reciprocated ties is, surprisingly, very low in our DLT 1 network.

And if we wanted to highlight this lack of reciprocity in a network visual, we can iterate through the edges of the graph to check if there is a reciprocal edge (an edge in the opposite direction) and then add an attribute to each edge indicating reciprocity.

```{python flag_mutual_dyads}

for u,v,k in dlt1_network.edges(keys=True):
  reciprocated = True if dlt1_network.has_edge(v, u) else False
  dlt1_network[u][v][k]['reciprocated'] = reciprocated
  

```

Let's the added attribute

```{python}
# Extract edges with their attributes
edges_data = list(dlt1_network.edges(data=True))

# Convert edges data to a DataFrame
edges_df = pd.DataFrame(edges_data, columns=['Source', 'Target', 'Attributes'])

# If you want to expand the attributes into separate columns, you can use pd.json_normalize
edges_df_expanded = pd.concat([edges_df.drop(columns=['Attributes']), edges_df['Attributes'].apply(pd.Series)], axis=1)

# Print the DataFrame to view it as a table
print(edges_df_expanded)
```

Let's now add this new variable to our sociogram to highlight reciprocated ties in our DLT 1 network:

```{python add_reciprocated_ties}
# Assuming dlt1_network is your directed graph and 'in_degree' and 'reciprocated' are edge attributes
plt.figure(figsize=(8, 6))

# Draw nodes with size based on in-degree
node_sizes = [dlt1_network.nodes[n]['in_degree'] * 100 for n in dlt1_network.nodes()]
nx.draw_networkx_nodes(dlt1_network, pos=nx.spring_layout(dlt1_network), node_size=node_sizes)

# Draw edges with reduced alpha and color based on reciprocated attribute
edge_colors = [dlt1_network.edges[e]['reciprocated'] for e in dlt1_network.edges()]
nx.draw_networkx_edges(dlt1_network, pos=nx.spring_layout(dlt1_network), alpha=0.2, edge_color=edge_colors)

# Customize the plot 
plt.title('Graph with Node Size by In-Degree and Edge Color by Reciprocation')
plt.colorbar(label='Reciprocated')
plt.axis('off')

# Show the plot
plt.show()
plt.clf()
```

As you can see, there only appear to be seven dyads with reciprocated ties!

#### 5. Transitivity & Clustering

Transitivity, also known as the "friend of a friend" phenomenon, focuses on triads, or any "triple" of actors, rather than dyads like reciprocity. Just like a networks tendency towards reciprocity, there is also a tendency toward transitivity. For example, in the figure below Teacher A collaborates with Teacher B and Teacher B collaborates with Teacher C, then Teacher A is more likely at some point to collaborates with Teacher C and "complete" the triangle and less likely to collaborate with Teacher E since they do now share a connection:

![](img/transitivity.png){width="60%"}

As Carolan points out, establishing a network's transitivity is important, as it is theoretically connected to actors' tendencies to divide into exclusive subgroups or cluster over time, especially around positive relations such as friendship. While the algorithms behind network transitivity are not trivial, the defining network transitivity is rather straightforward:

> Transitivity measures the probability that the adjacent vertices of a vertex are connected. This is sometimes also called the clustering coefficient.

The [`transitivity()`](https://igraph.org/r/html/latest/transitivity.html) function provides a convenient means to calculate a network-level transitive measures:

In Networkx, since transitivity cannot be implemented for multigraph type, we first convert the graph to a simple graph before computing transitivity

```{python compute_transitivity}

simple_graph = nx.Graph(dlt1_network)
transitivity = nx.transitivity(simple_graph)
print(transitivity)

```

For our particular network, a very small value of 8% is not too surprising since, again, this is rather large network.

#### 6. Diameter & Distance

Whereas transitivity focuses on the importance of certain configurations of triads, diameter and distance are more straightforward. A network's diameter simply refers to the longest path between any two actors. A related measure is the average path length, which measures the mean distance between all pairs of actors in the network.

Given that our graph is loosely connected, we will begin by identifying the largest strongly connected components using the `strongly_connected_components()` function. Next, we will create a subgraph using the `subgraph()` function and calculate both the diameter and the mean distance of that subgraph using the `diameter()` and `average_shortest_path_length()` functions, respectively.

Let's apply these functions to our `dlt1_network` object:

```{python compute_diameter}


# Extract largest strongly connected component and its subgraph
largest_scc_graph = dlt1_network.subgraph(max(nx.strongly_connected_components(dlt1_network), key=len))

# Calculate and print diameter and mean distance

print(nx.diameter(largest_scc_graph))
print(nx.average_shortest_path_length(largest_scc_graph))



```

Carolan notes that both diameter and average path length are important network-level structural properties. Similar to diameter and distance measures for our DLT 1 network above, he notes that a network with a large diameter and small average path length suggests a structure in which there are parts of the network that some network actors may be unable to access.

### ðŸ‘‰ Your Turn â¤µ

Use the code chunk below to calculate the following measures for the DLT 2 network, then answer the questions below:

1.  Size
2.  Centralization
3.  Density
4.  Reciprocity
5.  Transitivity & Clustering
6.  Diameter & Distance

<!-- -->

1.  How do network-level measures for DLT 1 and DLT 2 collaboration compare? What are some similarities and differences?

```{python analyze_dlt2}
#YOUR CODE HERE
# Display the number of nodes in the 'dlt2_network' graph

# Display the number of edges in the 'dlt2_network' graph

# Display the size of the graph in terms of edges,the same as the number of edges


# Display the degree of each node in the network

# Display the density of the graph

# Display the reciprocity of the graph

# Convert the directed graph 'dlt1_network' to an undirected graph 'simple_graph', calculate its transitivity, and display the transitivity value


# Extract the largest strongly connected component and create its subgraph


# Calculate and display the diameter and mean distance

```

## 4. Model

As highlighted inÂ [Chapter 3 of Data Science in Education Using R](https://datascienceineducation.com/c03.html), theÂ **Model**Â step of the data science process entails "using statistical models, from simple to complex, to understand trends and patterns in the data." The authors note that while descriptive statistics and data visualization during theÂ **Explore** step can help us to identify patterns and relationships in our data, statistical models can be used to help us determine if relationships, patterns and trends are actually meaningful.

We will not explore the use of models for SNA until Lab 4, but recall from above that our study was guided by the following questions:

1.  What are the patterns of peer interaction and the structure of peer networks that emerge over the course of a MOOC-Ed?

2.  To what extent do participant and network attributes (e.g., homophily, reciprocity, transitivity) account for the structure of these networks?

3.  To what extent do these networks result in the co-construction of new knowledge?

To address Question 1, actors in the network were categorized into distinct mutually exclusive groups using the core-periphery and regular equivalence functions of UCINET. The former used the CORR algorithm to divide the network into actors that are part of a densely connected subgroup, or "core", from those that are part of the sparsely connected periphery. Regular equivalence employs the REGE blockmodeling algorithm to partition, or group, actors in the network based on the similarity of their ties to others with similar ties. In essence, blockmodeling provides a systematic way for categorizing educators based on the ways in which they interacted with peers.

As we saw upon just a basic visual inspection of our network during the Explore section, there was a small core of highly connected participants surrounded by those on the "periphery," or edge, of the network with very few connections. In the DLT 2 course, those on the periphery made up roughly 90% of network! The study also found relatively high levels of reciprocation, but also found that roughly a quarter of participants were characterized as "brodcasters" -- educators who initiated a discussion thread, but neither reciprocated with those who replied, nor posted to threads initiated by others.

To address Question 2, this study use the exponential family of random graph models (ERGM; also known as p\* models), which provide a statistical approach to network modeling that addresses the complex dependencies within networks. ERGMs predict network ties and determine the statistical likelihood of a given network structure, based on an assumed dependency structure, the attributes of the individuals (e.g., gender, popularity, location, previous ties) and prior states of the network.

As highlighted inÂ [Chapter 3 of Data Science in Education Using R](https://datascienceineducation.com/c03.html), theÂ **Model**Â step of the data science process entails "using statistical models, from simple to complex, to understand trends and patterns in the data."

A developing area of network research is the advancement of statistical models and tools to examine network change over time [@carolan2014]. These models are used to empirically test if changes in key structure measures are statistically significant, and also explain potential mechanisms driving those changes. Stochastic actor-based models, for example, are a family of models that have the purpose of representing network dynamics on the basis of observed longitudinal data. These stochastic actor-based models allow users to test hypotheses about these tendencies toward reciprocity, homophily, and transitivity over time and to estimate parameters expressing their strengths while controlling for other tendencies ("confounders").

## 5. Communicate

The final step in the workflow/process is sharing the results of your analysis with wider audience. For now, we will wrap up this case study by converting our work into a webpage that can be used to communicate your learning and demonstrate some of your new R skills. To do so, you will need to "knit" your document by clicking the ![](img/knit.png){width="10%"} button in the menu bar at that the top of this file. This will do two things; it will:

1.  check through all your code for any errors; and,

2.  create a file in your directory that you can use to share you work through [Posit Cloud](https://posit.cloud/learn/guide#publish-from-cloud) (see screenshot example below to publish), [RPubs](#0) , [GitHub Pages](#0), [Quarto Pub](#0), or [other methods](#0).

### Knit and Publish

Complete the following steps to knit and publish your work:

1.  First, change the name of the `author:` in the [YAML header](https://bookdown.org/yihui/rmarkdown-cookbook/rmarkdown-anatomy.html#yaml-metadata) at the very top of this document to your name. The YAML header controls the style and feel for knitted document but doesn't actually display in the final output.

2.  Next, click the knit button in the toolbar above to "knit" your R Markdown document to a [HTML](https://bookdown.org/yihui/rmarkdown/html-document.html) file that will be saved in your R Project folder. You should see a formatted webpage appear in your Viewer tab in the lower right pan or in a new browser window. Let's us know if you run into any issues with knitting.

3.  Finally, publish your webpage on Posit Cloud by clicking the "Publish" button located in the Viewer Pane after you knit your document. See screenshot below.

![](img/knit-publish.png){width="80%"}

Congratulations, you've completed the case study! You're now ready to dig into the essential readings and try out your next SNA LASER Badge!

### References
